import streamlit as st
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import joblib
import numpy as np
from langchain_community.llms import Ollama
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser # æ­£ç¡®çš„å¯¼å…¥è·¯å¾„
import json

# --- 0. å…¨å±€è®¾ç½®ä¸èµ„æºåŠ è½½ ---

st.set_page_config(page_title="å»ºç­‘æ€§èƒ½ä¼˜åŒ–ä¸å†³ç­–æ”¯æŒç³»ç»Ÿ", layout="wide")

# --- 1. ä¿®æ­£åçš„æ¨¡å‹å®šä¹‰ ---

# ä¸º UDI å’Œ DGI å®šä¹‰ä¸€ä¸ªæ¨¡å‹ç±»
# è¿™ä¸ªç»“æ„ä¸æ‚¨çš„ UDI_train.py å’Œ DGI_train.py å®Œå…¨ä¸€è‡´
class UDI_DGI_Model(nn.Module):
    def __init__(self, input_features=10):
        super().__init__()
        self.layer1 = nn.Linear(input_features, 256)  
        self.layer2 = nn.Linear(256, 512)
        self.layer3 = nn.Linear(512, 256)
        self.output_layer = nn.Linear(256, 1)

    def forward(self, x):
        x = torch.relu(self.layer1(x))
        x = torch.relu(self.layer2(x))
        x = torch.relu(self.layer3(x))
        x = self.output_layer(x)
        # ç§»é™¤ .squeeze() ä»¥ä¾¿ .item() å¯ä»¥ç›´æ¥ä½¿ç”¨
        return x

# ä¸º CEUI å®šä¹‰ä¸€ä¸ªç‹¬ç«‹çš„ã€æ›´å¤æ‚çš„æ¨¡å‹ç±»
# è¿™ä¸ªç»“æ„ä¸æ‚¨çš„ CEUI_train.py å®Œå…¨ä¸€è‡´
class CEUI_Model(nn.Module):
    def __init__(self, input_features=10):
        super().__init__()
        self.layer1 = nn.Linear(input_features, 256)
        self.bn1 = nn.BatchNorm1d(256)
        self.dropout1 = nn.Dropout(0.3)
        self.layer2 = nn.Linear(256, 512)
        self.bn2 = nn.BatchNorm1d(512)
        self.dropout2 = nn.Dropout(0.3)
        self.layer3 = nn.Linear(512, 256)
        self.bn3 = nn.BatchNorm1d(256)
        self.output_layer = nn.Linear(256, 1)

    def forward(self, x):
        # ç¡®ä¿åœ¨æ¨ç†æ—¶ï¼Œè¾“å…¥æ˜¯äºŒç»´çš„ [batch_size, features]
        # BatchNorm1d å±‚æœŸæœ›è‡³å°‘äºŒç»´çš„è¾“å…¥
        if x.dim() == 1:
            x = x.unsqueeze(0)
            
        x = self.dropout1(torch.relu(self.bn1(self.layer1(x))))
        x = self.dropout2(torch.relu(self.bn2(self.layer2(x))))
        x = torch.relu(self.bn3(self.layer3(x)))
        x = self.output_layer(x)
        # ç§»é™¤ .squeeze() ä»¥ä¾¿ .item() å¯ä»¥ç›´æ¥ä½¿ç”¨
        return x

@st.cache_resource
def load_models_and_scaler():
    """åŠ è½½æ‰€æœ‰PyTorchæ¨¡å‹å’Œæ•°æ®æ ‡å‡†åŒ–Scaler"""
    try:
        # ä½¿ç”¨æ­£ç¡®çš„ç±»æ¥å®ä¾‹åŒ–æ¯ä¸ªæ¨¡å‹
        udi_model = UDI_DGI_Model(input_features=10)
        dgi_model = UDI_DGI_Model(input_features=10)
        ceui_model = CEUI_Model(input_features=10)

        # ç¡®å®šè®¾å¤‡
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        st.sidebar.success(f"æ¨¡å‹å°†è¿è¡Œåœ¨: {str(device).upper()}")

        # åŠ è½½æ¨¡å‹æƒé‡ï¼Œå¹¶æ˜ å°„åˆ°æ­£ç¡®çš„è®¾å¤‡
        udi_model.load_state_dict(torch.load("UDI_trained_model.pth", map_location=device))
        dgi_model.load_state_dict(torch.load("DGI_trained_model.pth", map_location=device))
        ceui_model.load_state_dict(torch.load("CEUI_trained_model.pth", map_location=device))

        # å°†æ¨¡å‹æœ¬èº«ä¹Ÿç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
        udi_model.to(device)
        dgi_model.to(device)
        ceui_model.to(device)

        # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ (å¯¹äºæœ‰Dropoutå’ŒBatchNormçš„æ¨¡å‹è‡³å…³é‡è¦)
        udi_model.eval()
        dgi_model.eval()
        ceui_model.eval()

        # åŠ è½½Scalerå¯¹è±¡
        scaler = joblib.load('scaler.pkl') 
        
        return udi_model, dgi_model, ceui_model, scaler, device
    except FileNotFoundError as e:
        st.error(f"åŠ è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}ã€‚è¯·ç¡®ä¿æ‰€æœ‰æ¨¡å‹æ–‡ä»¶ (UDI_trained_model.pth, DGI_trained_model.pth, CEUI_trained_model.pth) å’Œ scaler.pkl éƒ½åœ¨åº”ç”¨æ ¹ç›®å½•ä¸‹ã€‚")
        return None, None, None, None, None
    except Exception as e:
        st.error(f"åŠ è½½èµ„æºæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return None, None, None, None, None

@st.cache_data
def load_pareto_data():
    """åŠ è½½å¸•ç´¯æ‰˜è§£é›†æ•°æ®"""
    try:
        df = pd.read_csv("å¸•ç´¯æ‰˜è§£é›†.csv")
        return df
    except FileNotFoundError as e:
        st.error(f"åŠ è½½æ•°æ®æ–‡ä»¶æ—¶å‡ºé”™: {e}ã€‚è¯·ç¡®ä¿ 'å¸•ç´¯-æ‰˜è§£é›†.csv' æ–‡ä»¶å­˜åœ¨ã€‚")
        return pd.DataFrame()

# åŠ è½½æ‰€æœ‰èµ„æº
udi_model, dgi_model, ceui_model, scaler, device = load_models_and_scaler()
df_solutions = load_pareto_data()

# --- 2. åœºæ™¯ä¸€ï¼šå¿«é€Ÿæ€§èƒ½é¢„æµ‹é¡µé¢ ---

def prediction_page():
    st.header("åœºæ™¯ä¸€ï¼šå¿«é€Ÿæ€§èƒ½é¢„æµ‹")
    st.markdown("é€šè¿‡æ»‘å—è¾“å…¥å•ä¸ªè®¾è®¡æ–¹æ¡ˆçš„å‚æ•°ï¼Œç³»ç»Ÿå°†è°ƒç”¨é¢„æµ‹æ¨¡å‹è®¡ç®—å…¶æ€§èƒ½ã€‚")
    
    feature_names = ['å¼€é—´', 'è¿›æ·±', 'å±‚é«˜', 'åŒ—ä¾§çª—å°é«˜', 'åŒ—ä¾§çª—é«˜', 'åŒ—ä¾§çª—å¢™æ¯”', 'å—ä¾§çª—å¢™æ¯”', 'å—ä¾§çª—é«˜', 'å—ä¾§çª—å°é«˜', 'å—ä¾§çª—é—´è·']
    input_vars = {}
    
    st.info("è¯·æ‹–åŠ¨ä¸‹é¢çš„æ»‘å—æ¥è®¾ç½®è®¾è®¡å‚æ•°å€¼:")
    cols = st.columns(5)
    # è®¾å®šä¸€äº›æ›´åˆç†çš„é»˜è®¤å€¼å’ŒèŒƒå›´
    default_values = {'å¼€é—´': 7.2, 'è¿›æ·±': 9.0, 'å±‚é«˜': 3.6, 'åŒ—ä¾§çª—å°é«˜': 0.9, 'åŒ—ä¾§çª—é«˜': 1.8, 'åŒ—ä¾§çª—å¢™æ¯”': 0.3, 'å—ä¾§çª—å¢™æ¯”': 0.5, 'å—ä¾§çª—é«˜': 1.8, 'å—ä¾§çª—å°é«˜': 0.9, 'å—ä¾§çª—é—´è·': 1.2}
    min_max_step = {'å¼€é—´': (3.0, 10.0, 0.1), 'è¿›æ·±': (5.0, 12.0, 0.1), 'å±‚é«˜': (2.8, 5.0, 0.1), 'åŒ—ä¾§çª—å°é«˜': (0.5, 1.5, 0.1), 'åŒ—ä¾§çª—é«˜': (1.0, 3.0, 0.1), 'åŒ—ä¾§çª—å¢™æ¯”': (0.1, 0.8, 0.05), 'å—ä¾§çª—å¢™æ¯”': (0.1, 0.8, 0.05), 'å—ä¾§çª—é«˜': (1.0, 3.0, 0.1), 'å—ä¾§çª—å°é«˜': (0.5, 1.5, 0.1), 'å—ä¾§çª—é—´è·': (0.5, 3.0, 0.1)}

    for i, name in enumerate(feature_names):
        with cols[i % 5]:
            min_val, max_val, step_val = min_max_step[name]
            input_vars[name] = st.slider(f'{name}', min_value=min_val, max_value=max_val, value=default_values[name], step=step_val)

    if st.button("å¼€å§‹é¢„æµ‹", key="predict_button", use_container_width=True):
        if not all([udi_model, dgi_model, ceui_model, scaler, device]):
            st.error("æ¨¡å‹æˆ–ScaleræœªæˆåŠŸåŠ è½½ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨å¹¶åˆ·æ–°é¡µé¢ã€‚")
            return

        with st.spinner('æ­£åœ¨è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†å’Œæ¨¡å‹é¢„æµ‹...'):
            try:
                # 1. æ•´ç†è¾“å…¥æ•°æ®å¹¶ç¡®ä¿é¡ºåºæ­£ç¡®
                input_data = np.array([[input_vars[name] for name in feature_names]])
                
                # 2. ä½¿ç”¨åŠ è½½çš„scalerè¿›è¡Œæ ‡å‡†åŒ–
                scaled_data = scaler.transform(input_data)
                
                # 3. è½¬æ¢ä¸ºPyTorchå¼ é‡ï¼Œå¹¶ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
                input_tensor = torch.FloatTensor(scaled_data).to(device)

                # 4. è°ƒç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
                with torch.no_grad():
                    pred_udi = udi_model(input_tensor).item()
                    pred_dgi = dgi_model(input_tensor).item()
                    pred_ceui = ceui_model(input_tensor).item()
                
                st.subheader("ğŸš€ æ€§èƒ½é¢„æµ‹ç»“æœ:")
                c1, c2, c3 = st.columns(3)
                c1.metric("æœ‰æ•ˆé‡‡å…‰ç…§åº¦ (UDI)", f"{pred_udi:.2f} %")
                c2.metric("ä¸èˆ’é€‚çœ©å…‰æŒ‡æ•° (DGI)", f"{pred_dgi:.2f}")
                c3.metric("åˆ¶å†·èƒ½è€—å¼ºåº¦ (CEUI)", f"{pred_ceui:.2f} kWh/mÂ²")

            except Exception as e:
                st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

# --- 2. åœºæ™¯äºŒï¼šå¤šæ–¹æ¡ˆæ™ºèƒ½å†³ç­–é¡µé¢ (ä¼˜åŒ–åç‰ˆæœ¬ï¼Œæ— ç¡¬æ€§ç­›é€‰) ---
def decision_page():
    st.header("åœºæ™¯äºŒï¼šå¤šæ–¹æ¡ˆæ™ºèƒ½å†³ç­–")
    st.markdown("ç”¨è‡ªç„¶è¯­è¨€æè¿°æ‚¨çš„è®¾è®¡åå¥½ï¼ŒLLMå°†ä¸ºæ‚¨ä»å¸•ç´¯æ‰˜æœ€ä¼˜æ–¹æ¡ˆä¸­æ™ºèƒ½æ¨èã€‚")
    
    # é¢„è®¾çš„å¸•ç´¯æ‰˜è§£é›†åˆ—åä¸ç”¨æˆ·å‹å¥½åç§°çš„æ˜ å°„
    feature_names = ['å¼€é—´', 'è¿›æ·±', 'å±‚é«˜', 'åŒ—ä¾§çª—å°é«˜', 'åŒ—ä¾§çª—é«˜', 'åŒ—ä¾§çª—å¢™æ¯”', 'å—ä¾§çª—å¢™æ¯”', 'å—ä¾§çª—é«˜', 'å—ä¾§çª—å°é«˜', 'å—ä¾§çª—é—´è·']

    user_preference = st.text_area(
        "è¯·è¾“å…¥æ‚¨çš„è®¾è®¡åå¥½:",
        placeholder="ä¾‹å¦‚ï¼šæˆ‘å¸Œæœ›æ•™å®¤èƒ½å°½å¯èƒ½åœ°èŠ‚èƒ½ï¼ŒåŒæ—¶ä¸¥æ ¼æ§åˆ¶çœ©å…‰ï¼Œé‡‡å…‰è¾¾åˆ°è‰¯å¥½æ°´å¹³å³å¯ã€‚",
        height=150
    )

    if st.button("å¼€å§‹æ™ºèƒ½æ¨è", key="decision_button", use_container_width=True):
        if df_solutions.empty:
            st.error("å¸•ç´¯æ‰˜è§£é›†æ•°æ® ('å¸•ç´¯æ‰˜è§£é›†.csv') æœªæˆåŠŸåŠ è½½ï¼Œæ— æ³•è¿›è¡Œå†³ç­–ã€‚")
            return
        if not user_preference:
            st.warning("è¯·è¾“å…¥æ‚¨çš„è®¾è®¡åå¥½ï¼")
            return

        with st.spinner('AIä¸“å®¶æ­£åœ¨åˆ†ææ‚¨çš„åå¥½å¹¶è¿›è¡Œå†³ç­–...'):
            parser = JsonOutputParser()
            
            # --- è¿™æ˜¯ä¿®æ”¹çš„æ ¸å¿ƒéƒ¨åˆ†ï¼šæ–°çš„Promptæ¨¡æ¿ ---
            prompt_template = """
            ä½ æ˜¯ä¸€ä½é¡¶å°–çš„å»ºç­‘è®¾è®¡ä¸æ€§èƒ½ä¼˜åŒ–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è®¾è®¡åå¥½ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºä¸€ä¸ªåŒ…å«'weights'å’Œ'reasoning'çš„JSONå¯¹è±¡ã€‚
            
            # æŒ‡æ ‡å«ä¹‰è¯´æ˜ï¼š
            - UDI (æœ‰æ•ˆé‡‡å…‰ç…§åº¦): ä»£è¡¨å®¤å†…â€œé‡‡å…‰â€æ°´å¹³ï¼Œæ•°å€¼è¶Šé«˜è¶Šå¥½ã€‚
            - CEUI (åˆ¶å†·èƒ½è€—å¼ºåº¦): ä»£è¡¨å»ºç­‘â€œèƒ½è€—â€ï¼Œæ•°å€¼è¶Šä½è¶Šå¥½ã€‚
            - DGI (ä¸èˆ’é€‚çœ©å…‰æŒ‡æ•°): ä»£è¡¨å®¤å†…â€œçœ©å…‰â€ç¨‹åº¦ï¼Œæ•°å€¼è¶Šä½è¶Šå¥½ã€‚

            # ä½ çš„ä»»åŠ¡ï¼š
            1.  ä»”ç»†é˜…è¯»ç”¨æˆ·çš„åå¥½æè¿°: '{preference}'
            2.  **ä¸è¦ä½¿ç”¨ä»»ä½•ç¡¬æ€§ç­›é€‰æ¡ä»¶ã€‚**
            3.  ç”Ÿæˆä¸€ä¸ª'weights'å­—å…¸ï¼Œè¡¨è¾¾ä¸‰ä¸ªæŒ‡æ ‡çš„ç›¸å¯¹é‡è¦æ€§ã€‚æƒé‡è¶Šé«˜çš„æŒ‡æ ‡ï¼Œä»£è¡¨ç”¨æˆ·è¶Šå…³å¿ƒã€‚ä¸‰ä¸ªæƒé‡çš„æ€»å’Œå¿…é¡»ä¸º1.0ã€‚
            4.  ç”Ÿæˆä¸€ä¸ª'reasoning'å­—ç¬¦ä¸²ï¼Œç”¨ä¸€ä¸¤å¥è¯ç®€è¦è§£é‡Šä½ ä¸ºä»€ä¹ˆè¿™æ ·åˆ†é…æƒé‡ã€‚

            # ç¤ºä¾‹ï¼š
            å¦‚æœç”¨æˆ·è¯´ï¼š"æˆ‘æœ€å…³å¿ƒçš„æ˜¯èŠ‚èƒ½ï¼Œçœ©å…‰å…¶æ¬¡ï¼Œé‡‡å…‰å·®ä¸å¤šå°±è¡Œã€‚"
            ä½ çš„è¾“å‡ºåº”è¯¥æ˜¯ç±»ä¼¼è¿™æ ·çš„JSON:
            {{
                "weights": {{
                    "UDI": 0.2,
                    "CEUI": 0.5,
                    "DGI": 0.3
                }},
                "reasoning": "æ ¹æ®ç”¨æˆ·çš„æè¿°ï¼ŒèŠ‚èƒ½(CEUI)æ˜¯é¦–è¦ç›®æ ‡ï¼Œå› æ­¤åˆ†é…äº†æœ€é«˜æƒé‡ã€‚çœ©å…‰(DGI)ä¸ºæ¬¡è¦ç›®æ ‡ï¼Œé‡‡å…‰(UDI)è¦æ±‚ä¸é«˜ï¼Œæƒé‡æœ€ä½ã€‚"
            }}

            {format_instructions}
            """

            prompt = PromptTemplate(
                template=prompt_template,
                input_variables=["preference"],
                partial_variables={"format_instructions": parser.get_format_instructions()},
            )
            
            # ä½¿ç”¨æ‚¨æŒ‡å®šçš„deepseek-rlæ¨¡å‹
            llm = Ollama(model="deepseek-r1:7b")
            chain = prompt | llm | parser

            try:
                # è°ƒç”¨LLMè·å–å†³ç­–ç­–ç•¥
                decision_strategy = chain.invoke({"preference": user_preference})
                
                st.subheader("AIä¸“å®¶å¯¹æ‚¨åå¥½çš„è§£è¯»:")
                st.info(f"æ¨èç†ç”±: {decision_strategy.get('reasoning', 'æ— ')}")
                st.json({"weights": decision_strategy.get('weights')}) # åªæ˜¾ç¤ºæƒé‡éƒ¨åˆ†

                df_processed = df_solutions.copy()

                # --- æ ¸å¿ƒæ’åºé€»è¾‘ (å¯¹æ‰€æœ‰æ–¹æ¡ˆè¿›è¡Œæ“ä½œ) ---
                
                # 1. å½’ä¸€åŒ– (Normalization)
                # DGIå’ŒCEUIæ˜¯æˆæœ¬å‹æŒ‡æ ‡ï¼ˆè¶Šå°è¶Šå¥½ï¼‰ï¼ŒUDIæ˜¯æ•ˆç›Šå‹æŒ‡æ ‡ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
                # æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°†æ‰€æœ‰æŒ‡æ ‡éƒ½è½¬æ¢ä¸ºâ€œè¶Šå¤§è¶Šå¥½â€çš„å¾—åˆ†
                for col in ['UDI', 'DGI', 'CEUI']:
                    min_val, max_val = df_processed[col].min(), df_processed[col].max()
                    if (max_val - min_val) > 0:
                        if col == 'UDI': # æ•ˆç›Šå‹æŒ‡æ ‡ï¼Œç›´æ¥å½’ä¸€åŒ–
                            df_processed[f'{col}_norm'] = (df_processed[col] - min_val) / (max_val - min_val)
                        else: # æˆæœ¬å‹æŒ‡æ ‡ (DGI, CEUI)ï¼Œåå‘å½’ä¸€åŒ–
                            df_processed[f'{col}_norm'] = (max_val - df_processed[col]) / (max_val - min_val)
                    else:
                        # å¦‚æœä¸€ä¸ªæŒ‡æ ‡åœ¨æ‰€æœ‰æ–¹æ¡ˆä¸­éƒ½ä¸€æ ·ï¼Œé‚£ä¹ˆå®ƒçš„å½’ä¸€åŒ–å¾—åˆ†ä¸º1ï¼ˆæˆ–0.5ï¼‰ï¼Œä¸å½±å“æ’åº
                        df_processed[f'{col}_norm'] = 1.0

                # 2. åŠ æƒè¯„åˆ† (Weighted Scoring)
                weights = decision_strategy.get('weights', {})
                w_udi = weights.get('UDI', 1/3) # å¦‚æœLLMæ²¡ç»™ï¼Œå°±ç”¨é»˜è®¤ç­‰æƒé‡
                w_dgi = weights.get('DGI', 1/3)
                w_ceui = weights.get('CEUI', 1/3)
                
                # æ‰€æœ‰å½’ä¸€åŒ–åçš„æŒ‡æ ‡éƒ½æ˜¯â€œè¶Šå¤§è¶Šå¥½â€ï¼Œæ‰€ä»¥ç›´æ¥åŠ æƒæ±‚å’Œ
                df_processed['score'] = (
                    df_processed['UDI_norm'] * w_udi + 
                    df_processed['DGI_norm'] * w_dgi + 
                    df_processed['CEUI_norm'] * w_ceui
                )
                
                # 3. æ’åºå’Œå±•ç¤º (score è¶Šå¤§è¶Šå¥½)
                final_recommendations = df_processed.sort_values(by='score', ascending=False).head(5)
                
                st.subheader("ä¸ºæ‚¨æ¨èçš„æœ€ä½³5ä¸ªæ–¹æ¡ˆ:")
                # ç¡®ä¿åªå±•ç¤ºæ•°æ®é›†ä¸­å­˜åœ¨çš„åˆ—
                display_cols = ['UDI', 'DGI', 'CEUI', 'score'] + [col for col in feature_names if col in final_recommendations.columns]
                st.dataframe(final_recommendations[display_cols].style.format("{:.2f}"))

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦å¼€å¯ä¸”æ¨¡å‹åç§°'deepseek-rl:7b'æ˜¯å¦æ­£ç¡®: {e}")
                st.exception(e) # æ‰“å°è¯¦ç»†çš„é”™è¯¯å †æ ˆï¼Œæ–¹ä¾¿è°ƒè¯•

# --- 4. ä¸»ç¨‹åºä¸å¯¼èˆª ---
def main():
    st.sidebar.title("åŠŸèƒ½å¯¼èˆª")
    
    # æ£€æŸ¥èµ„æºæ˜¯å¦åŠ è½½æˆåŠŸ
    if not all([udi_model, dgi_model, ceui_model, scaler, device]):
        st.sidebar.error("æ ¸å¿ƒèµ„æºåŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æˆ–åˆ·æ–°ã€‚")
        st.header("ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
        st.write("æ— æ³•åŠ è½½å¿…è¦çš„æ¨¡å‹æˆ–æ•°æ®æ–‡ä»¶ï¼Œè¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶ä¸`app.py`åœ¨åŒä¸€ç›®å½•ä¸‹ï¼Œå¹¶æ£€æŸ¥ç»ˆç«¯é”™è¯¯ä¿¡æ¯ï¼š")
        st.code("""
- UDI_trained_model.pth
- DGI_trained_model.pth
- CEUI_trained_model.pth
- scaler.pkl
- å¸•ç´¯æ‰˜è§£é›†.csv
        """)
        return

    page_options = ["å¿«é€Ÿæ€§èƒ½é¢„æµ‹", "å¤šæ–¹æ¡ˆæ™ºèƒ½å†³ç­–"]
    page = st.sidebar.radio("è¯·é€‰æ‹©ä¸€ä¸ªåŠŸèƒ½åœºæ™¯", page_options)

    if page == "å¿«é€Ÿæ€§èƒ½é¢„æµ‹":
        prediction_page()
    elif page == "å¤šæ–¹æ¡ˆæ™ºèƒ½å†³ç­–":
        decision_page()

if __name__ == "__main__":
    main()