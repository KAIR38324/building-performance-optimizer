#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤æ¨¡å‹è¾“å‡ºèŒƒå›´é—®é¢˜
åˆ†æå½“å‰æ¨¡å‹è¾“å‡ºä¸å®é™…æ•°æ®èŒƒå›´çš„å·®å¼‚ï¼Œå¹¶æä¾›ä¿®å¤æ–¹æ¡ˆ
"""

import pickle
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler

# å®šä¹‰æ¨¡å‹ç±»
class UDI_DGI_Model(nn.Module):
    def __init__(self, input_features=10):
        super().__init__()
        self.layer1 = nn.Linear(input_features, 256)  
        self.layer2 = nn.Linear(256, 512)
        self.layer3 = nn.Linear(512, 256)
        self.output_layer = nn.Linear(256, 1)

    def forward(self, x):
        x = torch.relu(self.layer1(x))
        x = torch.relu(self.layer2(x))
        x = torch.relu(self.layer3(x))
        return self.output_layer(x)

def analyze_model_output():
    """åˆ†ææ¨¡å‹è¾“å‡ºä¸å®é™…æ•°æ®çš„å·®å¼‚"""
    try:
        print("ğŸ” åˆ†ææ¨¡å‹è¾“å‡ºé—®é¢˜...")
        
        # 1. åŠ è½½å®é™…æ•°æ®
        df = pd.read_csv('å¸•ç´¯æ‰˜è§£é›†.csv', encoding='utf-8')
        print(f"ğŸ“Š å®é™…UDIæ•°æ®èŒƒå›´: {df['UDI'].min():.2f} - {df['UDI'].max():.2f}")
        print(f"ğŸ“Š å®é™…UDIå‡å€¼: {df['UDI'].mean():.2f}")
        
        # 2. åŠ è½½æ¨¡å‹å’Œscaler
        with open('scaler.pkl', 'rb') as f:
            scaler = pickle.load(f)
        
        udi_model = UDI_DGI_Model(input_features=10)
        device = torch.device('cpu')
        udi_model.load_state_dict(torch.load('UDI_trained_model.pth', map_location=device))
        udi_model.eval()
        
        # 3. ä½¿ç”¨å®é™…æ•°æ®è¿›è¡Œé¢„æµ‹
        feature_names = [
            'å¼€é—´', 'è¿›æ·±', 'å±‚é«˜', 'åŒ—ä¾§çª—å°é«˜', 
            'åŒ—ä¾§çª—é«˜', 'åŒ—ä¾§çª—å¢™æ¯”', 'å—ä¾§çª—å¢™æ¯”',
            'å—ä¾§çª—é«˜', 'å—ä¾§çª—å°é«˜', 'å—ä¾§çª—é—´è·'
        ]
        
        X = df[feature_names].values
        y_actual = df['UDI'].values
        
        # æ ‡å‡†åŒ–è¾“å…¥æ•°æ®
        X_scaled = scaler.transform(X)
        
        # æ¨¡å‹é¢„æµ‹
        with torch.no_grad():
            input_tensor = torch.FloatTensor(X_scaled)
            y_pred = udi_model(input_tensor).numpy().flatten()
        
        print(f"ğŸ¤– æ¨¡å‹é¢„æµ‹èŒƒå›´: {y_pred.min():.2f} - {y_pred.max():.2f}")
        print(f"ğŸ¤– æ¨¡å‹é¢„æµ‹å‡å€¼: {y_pred.mean():.2f}")
        
        # 4. è®¡ç®—ç¼©æ”¾å› å­
        scale_factor = np.mean(y_actual) / np.mean(y_pred)
        print(f"ğŸ“ å»ºè®®ç¼©æ”¾å› å­: {scale_factor:.6f}")
        
        # 5. æµ‹è¯•ç¼©æ”¾åçš„æ•ˆæœ
        y_pred_scaled = y_pred * scale_factor
        print(f"âœ… ç¼©æ”¾åé¢„æµ‹èŒƒå›´: {y_pred_scaled.min():.2f} - {y_pred_scaled.max():.2f}")
        print(f"âœ… ç¼©æ”¾åé¢„æµ‹å‡å€¼: {y_pred_scaled.mean():.2f}")
        
        # 6. è®¡ç®—è¯¯å·®
        mae_original = np.mean(np.abs(y_pred - y_actual))
        mae_scaled = np.mean(np.abs(y_pred_scaled - y_actual))
        
        print(f"\nğŸ“Š è¯¯å·®åˆ†æ:")
        print(f"åŸå§‹é¢„æµ‹MAE: {mae_original:.2f}")
        print(f"ç¼©æ”¾åé¢„æµ‹MAE: {mae_scaled:.2f}")
        print(f"è¯¯å·®æ”¹å–„: {((mae_original - mae_scaled) / mae_original * 100):.1f}%")
        
        return scale_factor
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def create_fixed_prediction_function():
    """åˆ›å»ºä¿®å¤åçš„é¢„æµ‹å‡½æ•°"""
    scale_factor = analyze_model_output()
    
    if scale_factor is None:
        print("âŒ æ— æ³•ç¡®å®šç¼©æ”¾å› å­")
        return
    
    print(f"\nğŸ”§ åˆ›å»ºä¿®å¤åçš„é¢„æµ‹å‡½æ•°...")
    
    # åˆ›å»ºä¿®å¤è„šæœ¬
    fix_code = f'''
# ä¿®å¤åçš„UDIé¢„æµ‹å‡½æ•°
# ç¼©æ”¾å› å­: {scale_factor:.6f}

def predict_udi_fixed(input_data, scaler, model):
    """ä¿®å¤åçš„UDIé¢„æµ‹å‡½æ•°"""
    # æ ‡å‡†åŒ–è¾“å…¥
    scaled_data = scaler.transform(input_data)
    
    # æ¨¡å‹é¢„æµ‹
    with torch.no_grad():
        input_tensor = torch.FloatTensor(scaled_data)
        raw_prediction = model(input_tensor).item()
    
    # åº”ç”¨ç¼©æ”¾å› å­ä¿®å¤
    fixed_prediction = raw_prediction * {scale_factor:.6f}
    
    return fixed_prediction
'''
    
    with open('udi_prediction_fix.py', 'w', encoding='utf-8') as f:
        f.write(fix_code)
    
    print("âœ… ä¿®å¤ä»£ç å·²ä¿å­˜åˆ° udi_prediction_fix.py")
    print(f"ğŸ’¡ åœ¨app.pyä¸­ä½¿ç”¨ç¼©æ”¾å› å­ {scale_factor:.6f} æ¥ä¿®å¤UDIé¢„æµ‹")

def test_fixed_prediction():
    """æµ‹è¯•ä¿®å¤åçš„é¢„æµ‹"""
    scale_factor = 0.107  # åŸºäºåˆ†æå¾—å‡ºçš„å¤§æ¦‚å€¼
    
    try:
        # åŠ è½½æ¨¡å‹å’Œscaler
        with open('scaler.pkl', 'rb') as f:
            scaler = pickle.load(f)
        
        udi_model = UDI_DGI_Model(input_features=10)
        device = torch.device('cpu')
        udi_model.load_state_dict(torch.load('UDI_trained_model.pth', map_location=device))
        udi_model.eval()
        
        # æµ‹è¯•æ•°æ®
        test_data = np.array([[
            8.0, 8.0, 3.2, 0.9, 1.5, 0.3, 0.4, 1.8, 0.9, 1.0
        ]])
        
        # é¢„æµ‹
        scaled_data = scaler.transform(test_data)
        with torch.no_grad():
            input_tensor = torch.FloatTensor(scaled_data)
            raw_pred = udi_model(input_tensor).item()
        
        fixed_pred = raw_pred * scale_factor
        
        print(f"\nğŸ§ª ä¿®å¤æµ‹è¯•:")
        print(f"åŸå§‹é¢„æµ‹: {raw_pred:.2f}")
        print(f"ä¿®å¤åé¢„æµ‹: {fixed_pred:.2f}")
        print(f"æ˜¯å¦åœ¨åˆç†èŒƒå›´: {'âœ…' if 50 <= fixed_pred <= 65 else 'âŒ'}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹åˆ†æå’Œä¿®å¤æ¨¡å‹è¾“å‡ºé—®é¢˜...")
    create_fixed_prediction_function()
    print("\nğŸ§ª æµ‹è¯•ä¿®å¤æ•ˆæœ...")
    test_fixed_prediction()